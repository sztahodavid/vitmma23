{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPcgHp+wLf/GZaNMMK46o4x"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!wget http://lsa.tmit.bme.hu/files/wiki_train_doc2vec_text.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZqeBIi7NpRQh","executionInfo":{"status":"ok","timestamp":1699358316963,"user_tz":-60,"elapsed":31020,"user":{"displayName":"Dávid Sztahó","userId":"16552280281976628162"}},"outputId":"2c54df01-8fe1-4372-92b1-4430b7f6fc9e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-11-07 12:00:37--  http://lsa.tmit.bme.hu/files/wiki_train_doc2vec_text.txt\n","Resolving lsa.tmit.bme.hu (lsa.tmit.bme.hu)... 152.66.246.99\n","Connecting to lsa.tmit.bme.hu (lsa.tmit.bme.hu)|152.66.246.99|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 243973232 (233M) [text/plain]\n","Saving to: ‘wiki_train_doc2vec_text.txt’\n","\n","wiki_train_doc2vec_ 100%[===================>] 232.67M  8.28MB/s    in 30s     \n","\n","2023-11-07 12:01:08 (7.74 MB/s) - ‘wiki_train_doc2vec_text.txt’ saved [243973232/243973232]\n","\n"]}]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U1KO2HyNpyPC","executionInfo":{"status":"ok","timestamp":1699358468408,"user_tz":-60,"elapsed":4,"user":{"displayName":"Dávid Sztahó","userId":"16552280281976628162"}},"outputId":"8f47f623-e8b1-4290-ca9e-4e60c8c9a7dd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","execution_count":15,"metadata":{"id":"YPpl_oR5nvOh","executionInfo":{"status":"ok","timestamp":1699358473966,"user_tz":-60,"elapsed":251,"user":{"displayName":"Dávid Sztahó","userId":"16552280281976628162"}}},"outputs":[],"source":["from gensim.test.utils import datapath\n","from gensim import utils\n","\n","class MyCorpus:\n","    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n","\n","    def __iter__(self):\n","        corpus_path = datapath('/content/wiki_train_doc2vec_text.txt')\n","        for line in open(corpus_path):\n","            # assume there's one document per line, tokens separated by whitespace\n","            yield utils.simple_preprocess(line)"]},{"cell_type":"code","source":["import gensim.models\n","\n","sentences = MyCorpus()\n","model = gensim.models.Word2Vec(sentences=sentences)"],"metadata":{"id":"NQjTAHCdpiBe","executionInfo":{"status":"ok","timestamp":1699359119931,"user_tz":-60,"elapsed":644948,"user":{"displayName":"Dávid Sztahó","userId":"16552280281976628162"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for w in model.wv.most_similar(positive=['király'], topn=20):\n","  print(w)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiSD3xf-pkGl","executionInfo":{"status":"ok","timestamp":1699359261016,"user_tz":-60,"elapsed":254,"user":{"displayName":"Dávid Sztahó","userId":"16552280281976628162"}},"outputId":"640c407f-2566-4963-b272-1d47f28fc8ea"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["('királynak', 0.8022586107254028)\n","('királyt', 0.7918736338615417)\n","('királlyal', 0.7583029270172119)\n","('herceg', 0.7438232898712158)\n","('királyné', 0.7249489426612854)\n","('trón', 0.7246353626251221)\n","('ulászló', 0.7228331565856934)\n","('királynő', 0.7227612733840942)\n","('királyhoz', 0.7164027690887451)\n","('uralkodó', 0.716214120388031)\n","('henrik', 0.713676393032074)\n","('császár', 0.7059786915779114)\n","('trónt', 0.7007117867469788)\n","('ferdinánd', 0.6963745951652527)\n","('eduárd', 0.6831820011138916)\n","('fejedelem', 0.68222576379776)\n","('királyok', 0.6734300851821899)\n","('szultán', 0.668687105178833)\n","('trónra', 0.665826141834259)\n","('hunyadi', 0.6651430726051331)\n"]}]},{"cell_type":"code","source":["from sklearn.decomposition import IncrementalPCA    # inital reduction\n","from sklearn.manifold import TSNE                   # final reduction\n","import numpy as np                                  # array handling\n","\n","\n","def reduce_dimensions(model):\n","    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n","\n","    # extract the words & their vectors, as numpy arrays\n","    vectors = np.asarray(model.wv.vectors)\n","    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n","\n","    # reduce using t-SNE\n","    tsne = TSNE(n_components=num_dimensions, random_state=0)\n","    vectors = tsne.fit_transform(vectors)\n","\n","    x_vals = [v[0] for v in vectors]\n","    y_vals = [v[1] for v in vectors]\n","    return x_vals, y_vals, labels\n","\n","\n","x_vals, y_vals, labels = reduce_dimensions(model)\n","\n","def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n","    from plotly.offline import init_notebook_mode, iplot, plot\n","    import plotly.graph_objs as go\n","\n","    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n","    data = [trace]\n","\n","    if plot_in_notebook:\n","        init_notebook_mode(connected=True)\n","        iplot(data, filename='word-embedding-plot')\n","    else:\n","        plot(data, filename='word-embedding-plot.html')\n","\n","\n","def plot_with_matplotlib(x_vals, y_vals, labels):\n","    import matplotlib.pyplot as plt\n","    import random\n","\n","    random.seed(0)\n","\n","    plt.figure(figsize=(12, 12))\n","    plt.scatter(x_vals, y_vals)\n","\n","    #\n","    # Label randomly subsampled 25 data points\n","    #\n","    indices = list(range(len(labels)))\n","    selected_indices = random.sample(indices, 25)\n","    for i in selected_indices:\n","        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n","\n","try:\n","    get_ipython()\n","except Exception:\n","    plot_function = plot_with_matplotlib\n","else:\n","    plot_function = plot_with_plotly\n","\n","plot_function(x_vals, y_vals, labels)"],"metadata":{"id":"vAo6W1_6so5_"},"execution_count":null,"outputs":[]}]}